{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wMDVc2WGzA82"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "SEED = 1234\n",
    "\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 695.0
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 12573.0,
     "status": "ok",
     "timestamp": 1.57577341234E12,
     "user": {
      "displayName": "Danny Toeun Kim",
      "photoUrl": "https://lh4.googleusercontent.com/--snSJRfjKUA/AAAAAAAAAAI/AAAAAAAABA8/JS6ff2ex4nM/s64/photo.jpg",
      "userId": "18139933724497343240"
     },
     "user_tz": 0.0
    },
    "id": "E_g4GwtuzA87",
    "outputId": "dee0282d-c66b-42fe-ef96-d08a99870bb7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting transformers\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/70/1a/364556102943cacde1ee00fdcae3b1615b39e52649eddbf54953e5b144c9/transformers-2.2.1-py3-none-any.whl (364kB)\n",
      "\r",
      "\u001b[K     |█                               | 10kB 31.5MB/s eta 0:00:01\r",
      "\u001b[K     |█▉                              | 20kB 5.6MB/s eta 0:00:01\r",
      "\u001b[K     |██▊                             | 30kB 8.0MB/s eta 0:00:01\r",
      "\u001b[K     |███▋                            | 40kB 5.2MB/s eta 0:00:01\r",
      "\u001b[K     |████▌                           | 51kB 6.4MB/s eta 0:00:01\r",
      "\u001b[K     |█████▍                          | 61kB 7.6MB/s eta 0:00:01\r",
      "\u001b[K     |██████▎                         | 71kB 8.8MB/s eta 0:00:01\r",
      "\u001b[K     |███████▏                        | 81kB 9.8MB/s eta 0:00:01\r",
      "\u001b[K     |████████                        | 92kB 11.0MB/s eta 0:00:01\r",
      "\u001b[K     |█████████                       | 102kB 8.6MB/s eta 0:00:01\r",
      "\u001b[K     |█████████▉                      | 112kB 8.6MB/s eta 0:00:01\r",
      "\u001b[K     |██████████▊                     | 122kB 8.6MB/s eta 0:00:01\r",
      "\u001b[K     |███████████▊                    | 133kB 8.6MB/s eta 0:00:01\r",
      "\u001b[K     |████████████▋                   | 143kB 8.6MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████▌                  | 153kB 8.6MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████▍                 | 163kB 8.6MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████▎                | 174kB 8.6MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████▏               | 184kB 8.6MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████               | 194kB 8.6MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████              | 204kB 8.6MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████▉             | 215kB 8.6MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████▊            | 225kB 8.6MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████▋           | 235kB 8.6MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████▌          | 245kB 8.6MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████▌         | 256kB 8.6MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████▍        | 266kB 8.6MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████▎       | 276kB 8.6MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████████▏      | 286kB 8.6MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████████      | 296kB 8.6MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████████     | 307kB 8.6MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████████▉    | 317kB 8.6MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████████▊   | 327kB 8.6MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████████████▋  | 337kB 8.6MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████████████▌ | 348kB 8.6MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████████████▍| 358kB 8.6MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████████████| 368kB 8.6MB/s \n",
      "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.21.0)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from transformers) (4.28.1)\n",
      "Collecting regex\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e3/8e/cbf2295643d7265e7883326fb4654e643bfc93b3a8a8274d8010a39d8804/regex-2019.11.1-cp36-cp36m-manylinux1_x86_64.whl (643kB)\n",
      "\u001b[K     |████████████████████████████████| 645kB 75.9MB/s \n",
      "\u001b[?25hCollecting sentencepiece\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/14/3d/efb655a670b98f62ec32d66954e1109f403db4d937c50d779a75b9763a29/sentencepiece-0.1.83-cp36-cp36m-manylinux1_x86_64.whl (1.0MB)\n",
      "\u001b[K     |████████████████████████████████| 1.0MB 73.6MB/s \n",
      "\u001b[?25hRequirement already satisfied: boto3 in /usr/local/lib/python3.6/dist-packages (from transformers) (1.10.32)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.17.4)\n",
      "Collecting sacremoses\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/1f/8e/ed5364a06a9ba720fddd9820155cc57300d28f5f43a6fd7b7e817177e642/sacremoses-0.0.35.tar.gz (859kB)\n",
      "\u001b[K     |████████████████████████████████| 860kB 63.9MB/s \n",
      "\u001b[?25hRequirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.8)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2019.11.28)\n",
      "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n",
      "Requirement already satisfied: s3transfer<0.3.0,>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (0.2.1)\n",
      "Requirement already satisfied: botocore<1.14.0,>=1.13.32 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (1.13.32)\n",
      "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (0.9.4)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (1.12.0)\n",
      "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.0)\n",
      "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (0.14.0)\n",
      "Requirement already satisfied: python-dateutil<2.8.1,>=2.1; python_version >= \"2.7\" in /usr/local/lib/python3.6/dist-packages (from botocore<1.14.0,>=1.13.32->boto3->transformers) (2.6.1)\n",
      "Requirement already satisfied: docutils<0.16,>=0.10 in /usr/local/lib/python3.6/dist-packages (from botocore<1.14.0,>=1.13.32->boto3->transformers) (0.15.2)\n",
      "Building wheels for collected packages: sacremoses\n",
      "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for sacremoses: filename=sacremoses-0.0.35-cp36-none-any.whl size=883999 sha256=c018a3df4f9cf3c4bbececa2b54c59a47f2a0e574469d694f0b19f3d36a9f63b\n",
      "  Stored in directory: /root/.cache/pip/wheels/63/2a/db/63e2909042c634ef551d0d9ac825b2b0b32dede4a6d87ddc94\n",
      "Successfully built sacremoses\n",
      "Installing collected packages: regex, sentencepiece, sacremoses, transformers\n",
      "Successfully installed regex-2019.11.1 sacremoses-0.0.35 sentencepiece-0.1.83 transformers-2.2.1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<p style=\"color: red;\">\n",
       "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
       "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
       "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
       "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 231508/231508 [00:00<00:00, 900360.07B/s]\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers\n",
    "from transformers import BertTokenizer\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34.0
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 633.0,
     "status": "ok",
     "timestamp": 1.575763132991E12,
     "user": {
      "displayName": "Danny Toeun Kim",
      "photoUrl": "https://lh4.googleusercontent.com/--snSJRfjKUA/AAAAAAAAAAI/AAAAAAAABA8/JS6ff2ex4nM/s64/photo.jpg",
      "userId": "18139933724497343240"
     },
     "user_tz": 0.0
    },
    "id": "DsN4ctVtzA8-",
    "outputId": "a48e15a0-c33e-49b2-c6db-fc5dbc250acb"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30522"
      ]
     },
     "execution_count": 4,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tokenizer.vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34.0
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 465.0,
     "status": "ok",
     "timestamp": 1.57576313481E12,
     "user": {
      "displayName": "Danny Toeun Kim",
      "photoUrl": "https://lh4.googleusercontent.com/--snSJRfjKUA/AAAAAAAAAAI/AAAAAAAABA8/JS6ff2ex4nM/s64/photo.jpg",
      "userId": "18139933724497343240"
     },
     "user_tz": 0.0
    },
    "id": "qALlzqD5zA9B",
    "outputId": "3ae19a88-8437-4e70-ad0a-1deb7826b52c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['hello', 'world', 'how', 'are', 'you', '?']\n"
     ]
    }
   ],
   "source": [
    "tokens = tokenizer.tokenize('Hello WORLD how ARE yoU?')\n",
    "\n",
    "print(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34.0
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 627.0,
     "status": "ok",
     "timestamp": 1.575763136769E12,
     "user": {
      "displayName": "Danny Toeun Kim",
      "photoUrl": "https://lh4.googleusercontent.com/--snSJRfjKUA/AAAAAAAAAAI/AAAAAAAABA8/JS6ff2ex4nM/s64/photo.jpg",
      "userId": "18139933724497343240"
     },
     "user_tz": 0.0
    },
    "id": "ob52YlNIzA9E",
    "outputId": "3abe0ef5-0ef1-4034-a2c5-532bbd98c8db"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7592, 2088, 2129, 2024, 2017, 1029]\n"
     ]
    }
   ],
   "source": [
    "indexes = tokenizer.convert_tokens_to_ids(tokens)\n",
    "\n",
    "print(indexes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34.0
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 659.0,
     "status": "ok",
     "timestamp": 1.575763139544E12,
     "user": {
      "displayName": "Danny Toeun Kim",
      "photoUrl": "https://lh4.googleusercontent.com/--snSJRfjKUA/AAAAAAAAAAI/AAAAAAAABA8/JS6ff2ex4nM/s64/photo.jpg",
      "userId": "18139933724497343240"
     },
     "user_tz": 0.0
    },
    "id": "dkn4421ZzA9H",
    "outputId": "ce6d598a-c3cf-42ab-effe-7a9a63ba7737"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CLS] [SEP] [PAD] [UNK]\n"
     ]
    }
   ],
   "source": [
    "init_token = tokenizer.cls_token\n",
    "eos_token = tokenizer.sep_token\n",
    "pad_token = tokenizer.pad_token\n",
    "unk_token = tokenizer.unk_token\n",
    "\n",
    "print(init_token, eos_token, pad_token, unk_token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34.0
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 619.0,
     "status": "ok",
     "timestamp": 1.575763141278E12,
     "user": {
      "displayName": "Danny Toeun Kim",
      "photoUrl": "https://lh4.googleusercontent.com/--snSJRfjKUA/AAAAAAAAAAI/AAAAAAAABA8/JS6ff2ex4nM/s64/photo.jpg",
      "userId": "18139933724497343240"
     },
     "user_tz": 0.0
    },
    "id": "pR26mPNPzA9L",
    "outputId": "aa104262-3cf0-4948-c73f-0727bdc4b639"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "101 102 0 100\n"
     ]
    }
   ],
   "source": [
    "init_token_idx = tokenizer.convert_tokens_to_ids(init_token)\n",
    "eos_token_idx = tokenizer.convert_tokens_to_ids(eos_token)\n",
    "pad_token_idx = tokenizer.convert_tokens_to_ids(pad_token)\n",
    "unk_token_idx = tokenizer.convert_tokens_to_ids(unk_token)\n",
    "\n",
    "print(init_token_idx, eos_token_idx, pad_token_idx, unk_token_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34.0
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 472.0,
     "status": "ok",
     "timestamp": 1.575763142916E12,
     "user": {
      "displayName": "Danny Toeun Kim",
      "photoUrl": "https://lh4.googleusercontent.com/--snSJRfjKUA/AAAAAAAAAAI/AAAAAAAABA8/JS6ff2ex4nM/s64/photo.jpg",
      "userId": "18139933724497343240"
     },
     "user_tz": 0.0
    },
    "id": "o57i8hqnzA9N",
    "outputId": "c6df2d5e-2961-4c6d-831d-527fe63a6eb0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "101 102 0 100\n"
     ]
    }
   ],
   "source": [
    "init_token_idx = tokenizer.cls_token_id\n",
    "eos_token_idx = tokenizer.sep_token_id\n",
    "pad_token_idx = tokenizer.pad_token_id\n",
    "unk_token_idx = tokenizer.unk_token_id\n",
    "\n",
    "print(init_token_idx, eos_token_idx, pad_token_idx, unk_token_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34.0
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 486.0,
     "status": "ok",
     "timestamp": 1.575763144922E12,
     "user": {
      "displayName": "Danny Toeun Kim",
      "photoUrl": "https://lh4.googleusercontent.com/--snSJRfjKUA/AAAAAAAAAAI/AAAAAAAABA8/JS6ff2ex4nM/s64/photo.jpg",
      "userId": "18139933724497343240"
     },
     "user_tz": 0.0
    },
    "id": "5kn7tNNzzA9Q",
    "outputId": "aff08c85-a821-4ef9-8d19-149b22445927"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "512\n"
     ]
    }
   ],
   "source": [
    "max_input_length = tokenizer.max_model_input_sizes['bert-base-uncased']\n",
    "\n",
    "print(max_input_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OrNbtoByzA9T"
   },
   "outputs": [],
   "source": [
    "def tokenize_and_cut(sentence):\n",
    "    tokens = tokenizer.tokenize(sentence) \n",
    "    tokens = tokens[:max_input_length-2]\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7_-IHUE8zA9V"
   },
   "outputs": [],
   "source": [
    "from torchtext import data\n",
    "\n",
    "TEXT = data.Field(batch_first = True,\n",
    "                  use_vocab = False,\n",
    "                  tokenize = tokenize_and_cut,\n",
    "                  preprocessing = tokenizer.convert_tokens_to_ids,\n",
    "                  init_token = init_token_idx,\n",
    "                  eos_token = eos_token_idx,\n",
    "                  pad_token = pad_token_idx,\n",
    "                  unk_token = unk_token_idx)\n",
    "\n",
    "LABEL = data.LabelField(dtype = torch.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51.0
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 194386.0,
     "status": "ok",
     "timestamp": 1.575763344868E12,
     "user": {
      "displayName": "Danny Toeun Kim",
      "photoUrl": "https://lh4.googleusercontent.com/--snSJRfjKUA/AAAAAAAAAAI/AAAAAAAABA8/JS6ff2ex4nM/s64/photo.jpg",
      "userId": "18139933724497343240"
     },
     "user_tz": 0.0
    },
    "id": "3ltzZdjRzA9Y",
    "outputId": "40ca892a-69a1-4117-8c8f-4fdc39f9e5e4"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "aclImdb_v1.tar.gz:   0%|          | 0.00/84.1M [00:00<?, ?B/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "downloading aclImdb_v1.tar.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "aclImdb_v1.tar.gz: 100%|██████████| 84.1M/84.1M [00:03<00:00, 22.3MB/s]\n"
     ]
    }
   ],
   "source": [
    "from torchtext import datasets\n",
    "\n",
    "train_data, test_data = datasets.IMDB.splits(TEXT, LABEL)\n",
    "\n",
    "train_data, valid_data = train_data.split(random_state = random.seed(SEED))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68.0
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 478.0,
     "status": "ok",
     "timestamp": 1.575763403883E12,
     "user": {
      "displayName": "Danny Toeun Kim",
      "photoUrl": "https://lh4.googleusercontent.com/--snSJRfjKUA/AAAAAAAAAAI/AAAAAAAABA8/JS6ff2ex4nM/s64/photo.jpg",
      "userId": "18139933724497343240"
     },
     "user_tz": 0.0
    },
    "id": "3FtQBseJzA9b",
    "outputId": "8d54dd34-fb68-4c84-bfe8-851f09eaf555"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training examples: 17500\n",
      "Number of validation examples: 7500\n",
      "Number of testing examples: 25000\n"
     ]
    }
   ],
   "source": [
    "print(f\"Number of training examples: {len(train_data)}\")\n",
    "print(f\"Number of validation examples: {len(valid_data)}\")\n",
    "print(f\"Number of testing examples: {len(test_data)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54.0
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 546.0,
     "status": "ok",
     "timestamp": 1.575763406945E12,
     "user": {
      "displayName": "Danny Toeun Kim",
      "photoUrl": "https://lh4.googleusercontent.com/--snSJRfjKUA/AAAAAAAAAAI/AAAAAAAABA8/JS6ff2ex4nM/s64/photo.jpg",
      "userId": "18139933724497343240"
     },
     "user_tz": 0.0
    },
    "id": "6iJ9_BayzA9d",
    "outputId": "1ceffc21-e031-40e2-e393-727a952981ac"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'text': [3649, 1996, 22617, 1997, 1996, 2143, 1010, 2009, 2003, 9996, 18800, 1012, 2004, 2500, 2031, 4197, 2041, 1010, 1996, 3185, 3065, 10575, 1999, 4238, 4092, 1999, 5640, 1010, 2738, 2084, 4723, 1012, 2008, 2003, 2438, 2000, 4558, 21553, 2005, 3087, 2040, 2038, 1996, 15989, 3716, 1997, 1996, 2181, 2030, 1996, 2406, 1012, 1996, 5957, 2071, 2025, 2022, 2062, 2367, 2013, 1996, 5025, 1012, 1026, 7987, 1013, 1028, 1026, 7987, 1013, 1028, 2060, 25854, 10697, 1024, 1037, 3345, 2003, 3491, 2000, 2022, 4082, 1999, 7041, 1010, 2096, 7041, 2515, 2025, 2031, 7111, 1012, 1996, 5037, 6059, 2003, 4147, 1037, 10768, 2480, 1006, 1996, 2417, 6045, 1007, 1010, 6168, 1996, 10768, 2480, 2001, 7917, 2011, 4977, 2172, 2077, 1996, 2051, 1999, 2029, 1996, 3185, 2003, 2275, 1012, 1996, 5037, 6059, 1005, 1055, 2684, 2003, 2941, 5102, 2004, 2019, 2796, 1010, 1998, 2796, 4556, 2189, 2003, 2652, 1999, 1996, 4281, 1999, 2116, 5019, 1012, 1045, 6814, 1996, 16587, 3214, 2000, 2265, 2019, 12564, 2450, 1010, 1998, 18906, 2072, 2001, 2054, 2027, 2787, 2052, 2191, 2014, 12564, 1012], 'label': 'neg'}\n"
     ]
    }
   ],
   "source": [
    "print(vars(train_data.examples[6]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54.0
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 560.0,
     "status": "ok",
     "timestamp": 1.575763408718E12,
     "user": {
      "displayName": "Danny Toeun Kim",
      "photoUrl": "https://lh4.googleusercontent.com/--snSJRfjKUA/AAAAAAAAAAI/AAAAAAAABA8/JS6ff2ex4nM/s64/photo.jpg",
      "userId": "18139933724497343240"
     },
     "user_tz": 0.0
    },
    "id": "qrXBP84TzA9g",
    "outputId": "96532fb8-1588-4664-cf92-a5c16b91a24c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['whatever', 'the', 'merits', 'of', 'the', 'film', ',', 'it', 'is', 'poorly', 'researched', '.', 'as', 'others', 'have', 'pointed', 'out', ',', 'the', 'movie', 'shows', 'locals', 'in', 'iran', 'speaking', 'in', 'arabic', ',', 'rather', 'than', 'persian', '.', 'that', 'is', 'enough', 'to', 'lose', 'credibility', 'for', 'anyone', 'who', 'has', 'the', 'slightest', 'knowledge', 'of', 'the', 'area', 'or', 'the', 'country', '.', 'the', 'landscape', 'could', 'not', 'be', 'more', 'different', 'from', 'the', 'actual', '.', '<', 'br', '/', '>', '<', 'br', '/', '>', 'other', 'factual', 'errors', ':', 'a', 'train', 'is', 'shown', 'to', 'be', 'operating', 'in', 'afghanistan', ',', 'while', 'afghanistan', 'does', 'not', 'have', 'railways', '.', 'the', 'turkish', 'ambassador', 'is', 'wearing', 'a', 'fe', '##z', '(', 'the', 'red', 'hat', ')', ',', 'whereas', 'the', 'fe', '##z', 'was', 'banned', 'by', 'turkey', 'much', 'before', 'the', 'time', 'in', 'which', 'the', 'movie', 'is', 'set', '.', 'the', 'turkish', 'ambassador', \"'\", 's', 'daughter', 'is', 'actually', 'dressed', 'as', 'an', 'indian', ',', 'and', 'indian', 'classical', 'music', 'is', 'playing', 'in', 'the', 'background', 'in', 'many', 'scenes', '.', 'i', 'suppose', 'the', 'filmmakers', 'meant', 'to', 'show', 'an', 'exotic', 'woman', ',', 'and', 'sar', '##i', 'was', 'what', 'they', 'decided', 'would', 'make', 'her', 'exotic', '.']\n"
     ]
    }
   ],
   "source": [
    "tokens = tokenizer.convert_ids_to_tokens(vars(train_data.examples[6])['text'])\n",
    "\n",
    "print(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1D-cZIzTzA9j"
   },
   "outputs": [],
   "source": [
    "LABEL.build_vocab(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34.0
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 562.0,
     "status": "ok",
     "timestamp": 1.575763412012E12,
     "user": {
      "displayName": "Danny Toeun Kim",
      "photoUrl": "https://lh4.googleusercontent.com/--snSJRfjKUA/AAAAAAAAAAI/AAAAAAAABA8/JS6ff2ex4nM/s64/photo.jpg",
      "userId": "18139933724497343240"
     },
     "user_tz": 0.0
    },
    "id": "He7eGkbnzA9o",
    "outputId": "792e3fd2-7433-4a45-89cf-d8955480ef1f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "defaultdict(<function _default_unk_index at 0x7fed06473840>, {'neg': 0, 'pos': 1})\n"
     ]
    }
   ],
   "source": [
    "print(LABEL.vocab.stoi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XCAH8YT6zA9s"
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 128\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "train_iterator, valid_iterator, test_iterator = data.BucketIterator.splits(\n",
    "    (train_data, valid_data, test_data), \n",
    "    batch_size = BATCH_SIZE, \n",
    "    device = device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "k0IL387YzA9w"
   },
   "source": [
    "## Build the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51.0
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 20823.0,
     "status": "ok",
     "timestamp": 1.575774093106E12,
     "user": {
      "displayName": "Danny Toeun Kim",
      "photoUrl": "https://lh4.googleusercontent.com/--snSJRfjKUA/AAAAAAAAAAI/AAAAAAAABA8/JS6ff2ex4nM/s64/photo.jpg",
      "userId": "18139933724497343240"
     },
     "user_tz": 0.0
    },
    "id": "DRkdRyalzA9w",
    "outputId": "46751d36-60db-43ee-f43d-f9ecc1d55f83"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:00<00:00, 158399.75B/s]\n",
      "100%|██████████| 440473133/440473133 [00:14<00:00, 29503141.50B/s]\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertTokenizer, BertModel\n",
    "\n",
    "bert = BertModel.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9uw1neunzA9z"
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class BERTGRUSentiment(nn.Module):\n",
    "    def __init__(self,\n",
    "                 bert,\n",
    "                 hidden_dim,\n",
    "                 output_dim,\n",
    "                 n_layers,\n",
    "                 bidirectional,\n",
    "                 dropout):\n",
    "        \n",
    "        super().__init__()\n",
    "        \n",
    "        self.bert = bert\n",
    "        \n",
    "        embedding_dim = bert.config.to_dict()['hidden_size']\n",
    "        \n",
    "        self.rnn = nn.GRU(embedding_dim,\n",
    "                          hidden_dim,\n",
    "                          num_layers = n_layers,\n",
    "                          bidirectional = bidirectional,\n",
    "                          batch_first = True,\n",
    "                          dropout = 0 if n_layers < 2 else dropout)\n",
    "        \n",
    "        self.out = nn.Linear(hidden_dim * 2 if bidirectional else hidden_dim, output_dim)\n",
    "        \n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "    def forward(self, text):\n",
    "        \n",
    "        #text = [batch size, sent len]\n",
    "                \n",
    "        with torch.no_grad():\n",
    "            embedded = bert(text)[0]\n",
    "                \n",
    "        #embedded = [batch size, sent len, emb dim]\n",
    "        \n",
    "        _, hidden = self.rnn(embedded)\n",
    "        \n",
    "        #hidden = [n layers * n directions, batch size, emb dim]\n",
    "        \n",
    "        if self.rnn.bidirectional:\n",
    "            hidden = self.dropout(torch.cat((hidden[-2,:,:], hidden[-1,:,:]), dim = 1))\n",
    "        else:\n",
    "            hidden = self.dropout(hidden[-1,:,:])\n",
    "                \n",
    "        #hidden = [batch size, hid dim]\n",
    "        \n",
    "        output = self.out(hidden)\n",
    "        \n",
    "        #output = [batch size, out dim]\n",
    "        \n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jh35OycMzA91"
   },
   "outputs": [],
   "source": [
    "HIDDEN_DIM = 256\n",
    "OUTPUT_DIM = 1\n",
    "N_LAYERS = 2\n",
    "BIDIRECTIONAL = True\n",
    "DROPOUT = 0.25\n",
    "\n",
    "model = BERTGRUSentiment(bert,\n",
    "                         HIDDEN_DIM,\n",
    "                         OUTPUT_DIM,\n",
    "                         N_LAYERS,\n",
    "                         BIDIRECTIONAL,\n",
    "                         DROPOUT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34.0
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 475.0,
     "status": "ok",
     "timestamp": 1.575763439836E12,
     "user": {
      "displayName": "Danny Toeun Kim",
      "photoUrl": "https://lh4.googleusercontent.com/--snSJRfjKUA/AAAAAAAAAAI/AAAAAAAABA8/JS6ff2ex4nM/s64/photo.jpg",
      "userId": "18139933724497343240"
     },
     "user_tz": 0.0
    },
    "id": "zMnnAsgezA93",
    "outputId": "da78b3d7-77f9-411b-c7a9-5520e9d1cabd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model has 112,241,409 trainable parameters\n"
     ]
    }
   ],
   "source": [
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "print(f'The model has {count_parameters(model):,} trainable parameters')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_RmBsMXdzA96"
   },
   "outputs": [],
   "source": [
    "for name, param in model.named_parameters():                \n",
    "    if name.startswith('bert'):\n",
    "        param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34.0
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 463.0,
     "status": "ok",
     "timestamp": 1.575763444941E12,
     "user": {
      "displayName": "Danny Toeun Kim",
      "photoUrl": "https://lh4.googleusercontent.com/--snSJRfjKUA/AAAAAAAAAAI/AAAAAAAABA8/JS6ff2ex4nM/s64/photo.jpg",
      "userId": "18139933724497343240"
     },
     "user_tz": 0.0
    },
    "id": "7Bl5GecpzA99",
    "outputId": "253ad1e6-8128-474d-ccf5-009d9c6aa4f3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model has 2,759,169 trainable parameters\n"
     ]
    }
   ],
   "source": [
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "print(f'The model has {count_parameters(model):,} trainable parameters')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 323.0
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 459.0,
     "status": "ok",
     "timestamp": 1.57576344731E12,
     "user": {
      "displayName": "Danny Toeun Kim",
      "photoUrl": "https://lh4.googleusercontent.com/--snSJRfjKUA/AAAAAAAAAAI/AAAAAAAABA8/JS6ff2ex4nM/s64/photo.jpg",
      "userId": "18139933724497343240"
     },
     "user_tz": 0.0
    },
    "id": "CfxRQfq1zA-A",
    "outputId": "0072e7f3-8669-40a2-adf4-5f729d0271e4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rnn.weight_ih_l0\n",
      "rnn.weight_hh_l0\n",
      "rnn.bias_ih_l0\n",
      "rnn.bias_hh_l0\n",
      "rnn.weight_ih_l0_reverse\n",
      "rnn.weight_hh_l0_reverse\n",
      "rnn.bias_ih_l0_reverse\n",
      "rnn.bias_hh_l0_reverse\n",
      "rnn.weight_ih_l1\n",
      "rnn.weight_hh_l1\n",
      "rnn.bias_ih_l1\n",
      "rnn.bias_hh_l1\n",
      "rnn.weight_ih_l1_reverse\n",
      "rnn.weight_hh_l1_reverse\n",
      "rnn.bias_ih_l1_reverse\n",
      "rnn.bias_hh_l1_reverse\n",
      "out.weight\n",
      "out.bias\n"
     ]
    }
   ],
   "source": [
    "for name, param in model.named_parameters():                \n",
    "    if param.requires_grad:\n",
    "        print(name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "iH6oWmVqzA-B"
   },
   "source": [
    "## Train the Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WBVtko6AzA-C"
   },
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "optimizer = optim.Adam(model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kkl2PbFlzA-E"
   },
   "outputs": [],
   "source": [
    "criterion = nn.BCEWithLogitsLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dRV-6mllzA-H"
   },
   "outputs": [],
   "source": [
    "model = model.to(device)\n",
    "criterion = criterion.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7fDBRF-9zA-K"
   },
   "outputs": [],
   "source": [
    "def binary_accuracy(preds, y):\n",
    "    \"\"\"\n",
    "    Returns accuracy per batch, i.e. if you get 8/10 right, this returns 0.8, NOT 8\n",
    "    \"\"\"\n",
    "\n",
    "    #round predictions to the closest integer\n",
    "    rounded_preds = torch.round(torch.sigmoid(preds))\n",
    "    correct = (rounded_preds == y).float() #convert into float for division \n",
    "    acc = correct.sum() / len(correct)\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nqAmcoBazA-N"
   },
   "outputs": [],
   "source": [
    "def train(model, iterator, optimizer, criterion):\n",
    "    \n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    \n",
    "    model.train()\n",
    "    \n",
    "    for batch in iterator:\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        predictions = model(batch.text).squeeze(1)\n",
    "        \n",
    "        loss = criterion(predictions, batch.label)\n",
    "        \n",
    "        acc = binary_accuracy(predictions, batch.label)\n",
    "        \n",
    "        loss.backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "        \n",
    "        epoch_loss += loss.item()\n",
    "        epoch_acc += acc.item()\n",
    "        \n",
    "    return epoch_loss / len(iterator), epoch_acc / len(iterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "oq_j_oeizA-P"
   },
   "outputs": [],
   "source": [
    "def evaluate(model, iterator, criterion):\n",
    "    \n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    \n",
    "    model.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "    \n",
    "        for batch in iterator:\n",
    "\n",
    "            predictions = model(batch.text).squeeze(1)\n",
    "            \n",
    "            loss = criterion(predictions, batch.label)\n",
    "            \n",
    "            acc = binary_accuracy(predictions, batch.label)\n",
    "\n",
    "            epoch_loss += loss.item()\n",
    "            epoch_acc += acc.item()\n",
    "        \n",
    "    return epoch_loss / len(iterator), epoch_acc / len(iterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "I21mL2lhzA-Q"
   },
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "def epoch_time(start_time, end_time):\n",
    "    elapsed_time = end_time - start_time\n",
    "    elapsed_mins = int(elapsed_time / 60)\n",
    "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
    "    return elapsed_mins, elapsed_secs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 122.0
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 30584.0,
     "status": "ok",
     "timestamp": 1.575773455031E12,
     "user": {
      "displayName": "Danny Toeun Kim",
      "photoUrl": "https://lh4.googleusercontent.com/--snSJRfjKUA/AAAAAAAAAAI/AAAAAAAABA8/JS6ff2ex4nM/s64/photo.jpg",
      "userId": "18139933724497343240"
     },
     "user_tz": 0.0
    },
    "id": "xqhn28-Y4eim",
    "outputId": "8314a225-fd31-4019-ec3d-d8fc8ff15e7d",
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
      "\n",
      "Enter your authorization code:\n",
      "··········\n",
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54.0
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 654.0,
     "status": "ok",
     "timestamp": 1.57576458985E12,
     "user": {
      "displayName": "Danny Toeun Kim",
      "photoUrl": "https://lh4.googleusercontent.com/--snSJRfjKUA/AAAAAAAAAAI/AAAAAAAABA8/JS6ff2ex4nM/s64/photo.jpg",
      "userId": "18139933724497343240"
     },
     "user_tz": 0.0
    },
    "id": "Jdk1d0_93lVv",
    "outputId": "d82804a8-f22d-4d39-cd60-fcc415514739",
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<_io.TextIOWrapper name='/content/drive/My Drive/Colab Notebooks/Starry-night-in-the-winter-mountains.jpg' mode='r' encoding='UTF-8'>"
      ]
     },
     "execution_count": 40,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 612.0
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2213545.0,
     "status": "ok",
     "timestamp": 1.57576682843E12,
     "user": {
      "displayName": "Danny Toeun Kim",
      "photoUrl": "https://lh4.googleusercontent.com/--snSJRfjKUA/AAAAAAAAAAI/AAAAAAAABA8/JS6ff2ex4nM/s64/photo.jpg",
      "userId": "18139933724497343240"
     },
     "user_tz": 0.0
    },
    "id": "mJdVHGFXzA-S",
    "outputId": "19432eb9-7f15-4ffa-afa4-c2a6ba2f7a99"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "hell\n",
      "2\n",
      "3\n",
      "4\n",
      "\tTrain Loss: 0.279 | Train Acc: 88.70%\n",
      "\t Val. Loss: 0.237 |  Val. Acc: 89.87%\n",
      "1\n",
      "hell\n",
      "2\n",
      "3\n",
      "4\n",
      "\tTrain Loss: 0.236 | Train Acc: 90.67%\n",
      "\t Val. Loss: 0.247 |  Val. Acc: 90.12%\n",
      "1\n",
      "hell\n",
      "2\n",
      "3\n",
      "4\n",
      "\tTrain Loss: 0.212 | Train Acc: 91.62%\n",
      "\t Val. Loss: 0.231 |  Val. Acc: 91.14%\n",
      "1\n",
      "hell\n",
      "2\n",
      "3\n",
      "4\n",
      "\tTrain Loss: 0.189 | Train Acc: 92.67%\n",
      "\t Val. Loss: 0.246 |  Val. Acc: 90.37%\n",
      "1\n",
      "hell\n",
      "2\n",
      "3\n",
      "4\n",
      "\tTrain Loss: 0.160 | Train Acc: 93.84%\n",
      "\t Val. Loss: 0.224 |  Val. Acc: 91.04%\n"
     ]
    }
   ],
   "source": [
    "N_EPOCHS = 5\n",
    "\n",
    "best_valid_loss = float('inf')\n",
    "\n",
    "for epoch in range(N_EPOCHS):\n",
    "    \n",
    "    #start_time = time.time()\n",
    "    print(\"1\")\n",
    "    train_loss, train_acc = train(model, train_iterator, optimizer, criterion)\n",
    "    print(\"hell\")\n",
    "    valid_loss, valid_acc = evaluate(model, valid_iterator, criterion)\n",
    "    print(\"2\")\n",
    "    #end_time = time.time()\n",
    "    print(\"3\")\n",
    "    #epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
    "    print(\"4\")\n",
    "    if valid_loss < best_valid_loss:\n",
    "        best_valid_loss = valid_loss\n",
    "        torch.save(model.state_dict(), './Bert-model.pt')\n",
    "    \n",
    "    #print(f'Epoch: {epoch+1:02} | Epoch Time: {epoch_mins}m {epoch_secs}s')\n",
    "    print(f'\\tTrain Loss: {train_loss:.3f} | Train Acc: {train_acc*100:.2f}%')\n",
    "    print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. Acc: {valid_acc*100:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vTC59Ed4zA-U"
   },
   "source": [
    "We'll load up the parameters that gave us the best validation loss and try these on the test set - which gives us our best results so far!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34.0
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1371.0,
     "status": "ok",
     "timestamp": 1.575774238773E12,
     "user": {
      "displayName": "Danny Toeun Kim",
      "photoUrl": "https://lh4.googleusercontent.com/--snSJRfjKUA/AAAAAAAAAAI/AAAAAAAABA8/JS6ff2ex4nM/s64/photo.jpg",
      "userId": "18139933724497343240"
     },
     "user_tz": 0.0
    },
    "id": "EiykE9iezA-V",
    "outputId": "244a5166-81a5-4e45-910e-70624256154c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 11,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(torch.load('./Bert-model.pt'))\n",
    "\n",
    "test_loss, test_acc = evaluate(model, test_iterator, criterion)\n",
    "\n",
    "print(f'Test Loss: {test_loss:.3f} | Test Acc: {test_acc*100:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pP3xrlpCzA-Y"
   },
   "source": [
    "## Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Cnj1_oEezA-Z"
   },
   "outputs": [],
   "source": [
    "def predict_sentiment(model, tokenizer, sentence):\n",
    "    model.eval()\n",
    "    tokens = tokenizer.tokenize(sentence)\n",
    "    tokens = tokens[:max_input_length-2]\n",
    "    indexed = [init_token_idx] + tokenizer.convert_tokens_to_ids(tokens) + [eos_token_idx]\n",
    "    tensor = torch.LongTensor(indexed).to(device)\n",
    "    tensor = tensor.unsqueeze(0)\n",
    "    prediction = torch.sigmoid(model(tensor))\n",
    "    return prediction.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "db4pj2TizA-c",
    "outputId": "a36d234a-66a5-47e9-922d-98483b67bad6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9411056041717529"
      ]
     },
     "execution_count": 38,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_sentiment(model, tokenizer, \"This film is great\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_sentiment(model, tokenizer, \"This film is so bad!\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "6 - Transformers for Sentiment Analysis.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
